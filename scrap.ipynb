{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b24a0db",
   "metadata": {},
   "source": [
    "# Medium Scraping\n",
    "\n",
    "This notebook teach you how to collect articles data from Medium, filtering with tags and release date, and put it into a csv file.\n",
    "\n",
    "It was constructed based on [Dorian Lazar](https://dorianlazar.medium.com/) article that can be found \n",
    "[Here](https://dorianlazar.medium.com/scraping-medium-with-python-beautiful-soup-3314f898bbf5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b79c88",
   "metadata": {},
   "source": [
    "## Scraping stages\n",
    "\n",
    "1. Create Filters\n",
    "2. Get all articles with selected tags and release date\n",
    "3. Iterates articles getting usefull infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab750d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tools\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f02cd",
   "metadata": {},
   "source": [
    "## Create filters\n",
    "\n",
    "We need two three filtes.\n",
    "\n",
    "### tag_urls\n",
    "A dictionary named 'urls', where the key is the tag name and the values reference the url that access the Medium archives of an specific tag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089b0562",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_urls = {\n",
    "    'Data Science': 'https://medium.com/tag/data-science/archive/{0}/{1:02d}/{2:02d}',\n",
    "    'Machine Learning': 'https://medium.com/tag/machine-learning/archive/{0}/{1:02d}/{2:02d}',\n",
    "    'Artificial Inteligence': 'https://medium.com/tag/artificial-intelligence/archive/{0}/{1:02d}/{2:02d}',\n",
    "    'Deep Learning': 'https://medium.com/tag/deep-learning/archive/{0}/{1:02d}/{2:02d}',\n",
    "    'Data': 'https://medium.com/tag/data/archive/{0}/{1:02d}/{2:02d}',\n",
    "    'Big Data': 'https://medium.com/tag/big-data/archive/{0}/{1:02d}/{2:02d}',\n",
    "    'Analytics': 'https://medium.com/tag/analytics/archive/{0}/{1:02d}/{2:02d}',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8e3d2",
   "metadata": {},
   "source": [
    "### year\n",
    "\n",
    "A integer that represents our articles release year.\n",
    "\n",
    "### selected_days\n",
    "\n",
    "This one is a bit more trick, it is a list on integers that represents the day of the year in sequential order.\n",
    "\n",
    "Where 1 represents january 1, and 366 represents December 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8b79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "selected_days = [i for i in range(1, 366)] #Every day of the year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39bc90",
   "metadata": {},
   "source": [
    "## Create support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b19d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_day(day):\n",
    "    # if it is a leap year use month_days = [31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    month_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    m = 0\n",
    "    d = 0\n",
    "    while day > 0:\n",
    "        d = day\n",
    "        day -= month_days[m]\n",
    "        m += 1\n",
    "    return (m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0c774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claps(claps_str):\n",
    "    if (claps_str is None) or (claps_str == '') or (claps_str.split is None):\n",
    "        return 0\n",
    "    split = claps_str.split('K')\n",
    "    claps = float(split[0])\n",
    "    claps = int(claps*1000) if len(split) == 2 else int(claps)\n",
    "    return claps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a39f9f",
   "metadata": {},
   "source": [
    "## Collect Data\n",
    "\n",
    "Collect Medium data, and put it into a list called articles_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "089a38c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-07\n",
      "2020-09-08\n",
      "2020-09-09\n",
      "2020-09-10\n",
      "2020-09-11\n",
      "2020-09-12\n",
      "2020-09-13\n",
      "2020-09-14\n",
      "2020-09-15\n",
      "2020-09-16\n",
      "2020-09-17\n",
      "2020-09-18\n",
      "2020-09-19\n",
      "2020-09-20\n",
      "2020-09-21\n",
      "2020-09-22\n",
      "2020-09-23\n",
      "2020-09-24\n",
      "2020-09-25\n",
      "2020-09-26\n",
      "2020-09-27\n",
      "2020-09-28\n",
      "2020-09-29\n",
      "2020-09-30\n",
      "2020-10-01\n",
      "2020-10-02\n",
      "2020-10-03\n",
      "2020-10-04\n",
      "2020-10-05\n",
      "2020-10-06\n",
      "2020-10-07\n",
      "2020-10-08\n",
      "2020-10-09\n",
      "2020-10-10\n",
      "2020-10-11\n",
      "2020-10-12\n",
      "2020-10-13\n",
      "2020-10-14\n",
      "2020-10-15\n",
      "2020-10-16\n",
      "2020-10-17\n",
      "2020-10-18\n",
      "2020-10-19\n",
      "2020-10-20\n",
      "2020-10-21\n",
      "2020-10-22\n",
      "2020-10-23\n",
      "2020-10-24\n",
      "2020-10-25\n",
      "2020-10-26\n",
      "2020-10-27\n",
      "2020-10-28\n",
      "2020-10-29\n",
      "2020-10-30\n",
      "2020-10-31\n",
      "2020-11-01\n",
      "2020-11-02\n",
      "2020-11-03\n",
      "2020-11-04\n",
      "2020-11-05\n",
      "2020-11-06\n",
      "2020-11-07\n",
      "2020-11-08\n",
      "2020-11-09\n",
      "2020-11-10\n",
      "2020-11-11\n",
      "2020-11-12\n",
      "2020-11-13\n",
      "2020-11-14\n",
      "2020-11-15\n",
      "2020-11-16\n",
      "2020-11-17\n",
      "2020-11-18\n",
      "2020-11-19\n",
      "2020-11-20\n",
      "2020-11-21\n",
      "2020-11-22\n",
      "2020-11-23\n",
      "2020-11-24\n",
      "2020-11-25\n",
      "2020-11-26\n",
      "2020-11-27\n",
      "2020-11-28\n",
      "2020-11-29\n",
      "2020-11-30\n",
      "2020-12-01\n",
      "2020-12-02\n",
      "2020-12-03\n",
      "2020-12-04\n",
      "2020-12-05\n",
      "2020-12-06\n",
      "2020-12-07\n",
      "2020-12-08\n",
      "2020-12-09\n",
      "2020-12-10\n",
      "2020-12-11\n",
      "2020-12-12\n",
      "2020-12-13\n",
      "2020-12-14\n",
      "2020-12-15\n",
      "2020-12-16\n",
      "2020-12-17\n",
      "2020-12-18\n",
      "2020-12-19\n",
      "2020-12-20\n",
      "2020-12-21\n",
      "2020-12-22\n",
      "2020-12-23\n",
      "2020-12-24\n",
      "2020-12-25\n",
      "2020-12-26\n",
      "2020-12-27\n",
      "2020-12-28\n",
      "2020-12-29\n",
      "2020-12-30\n",
      "2020-12-31\n"
     ]
    }
   ],
   "source": [
    "articles_data = []\n",
    "article_id = 0\n",
    "n = len(selected_days)\n",
    "for d in selected_days:\n",
    "    month, day = convert_day(d)\n",
    "    date = '{0}-{1:02d}-{2:02d}'.format(year, month, day) \n",
    "    print(f'{date}')\n",
    "    for tag, url in tag_urls.items(): \n",
    "        response = requests.get(url.format(year, month, day), allow_redirects=True)\n",
    "        if not response.url.startswith(url.format(year, month, day)):\n",
    "            continue\n",
    "        page = response.content\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        articles = soup.find_all(\n",
    "            \"div\",\n",
    "            class_=\"postArticle postArticle--short js-postArticle js-trackPostPresentation js-trackPostScrolls\")\n",
    "        \n",
    "        for article in articles:\n",
    "            \n",
    "            title = article.find(\"h3\", class_=\"graf--title\")\n",
    "            if title is None:\n",
    "                continue\n",
    "            title = title.contents[0]\n",
    "            \n",
    "            author = article.find_all(\"a\")[0]['href'].split('?')[0].split('@')[1]\n",
    "            author_url = article.find_all(\"a\")[0]['href'].split('?')[0]\n",
    "            \n",
    "            subtitle = article.find(\"h4\", class_=\"graf--subtitle\")\n",
    "            subtitle = subtitle.contents[0] if subtitle is not None else ''\n",
    "            \n",
    "            article_url = article.find_all(\"a\")[3]['href'].split('?')[0]\n",
    "            \n",
    "            claps = get_claps(article.find_all(\"button\")[1].contents[0])\n",
    "            \n",
    "            reading_time = article.find(\"span\", class_=\"readingTime\")\n",
    "            reading_time = 0 if reading_time is None else int(reading_time['title'].split(' ')[0])\n",
    "            \n",
    "            responses = article.find_all(\"a\")\n",
    "            if len(responses) == 7:\n",
    "                responses = responses[6].contents[0].split(' ')\n",
    "                if len(responses) == 0:\n",
    "                    responses = 0\n",
    "                else:\n",
    "                    responses = responses[0]\n",
    "            else:\n",
    "                responses = 0\n",
    "\n",
    "            articles_data.append([article_url, title,\n",
    "                         author, author_url,\n",
    "                         subtitle, claps, responses,\n",
    "                         reading_time, tag, date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc37c8fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform article data into panda dataframe.\n",
    "medium_df = pd.DataFrame(articles_data, columns=[\n",
    "    'url', 'title', 'author', 'author_page',\n",
    "    'subtitle', 'claps', 'responses', 'reading_time',\n",
    "    'tag', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea7feff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b7d1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_day(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d9b67d",
   "metadata": {},
   "source": [
    "## Remove duplicated data\n",
    "\n",
    "As we can search about similar tags, it can bring the same articles in different iteration, so we need to clean our collected data.\n",
    "\n",
    "We do it using the panda fucntion drop_duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8859b426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51869, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12b9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_df = medium_df.drop_duplicates(subset=['url', 'title'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44beade7",
   "metadata": {},
   "source": [
    "## The final data\n",
    "\n",
    "Lets take a look of how our collected data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66548f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34053, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc1aa138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>author_page</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>claps</th>\n",
       "      <th>responses</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>tag</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://towardsdatascience.com/text-classifica...</td>\n",
       "      <td>BERT for Text Classification with NO model tra...</td>\n",
       "      <td>mdipietro09</td>\n",
       "      <td>https://towardsdatascience.com/@mdipietro09</td>\n",
       "      <td>Use BERT, Word Embedding, and Vector Similarity…</td>\n",
       "      <td>278</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://towardsdatascience.com/predictive-main...</td>\n",
       "      <td>Predictive maintenance of turbofan engines</td>\n",
       "      <td>kpeters_</td>\n",
       "      <td>https://towardsdatascience.com/@kpeters_</td>\n",
       "      <td></td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://towardsdatascience.com/minimal-pytorch...</td>\n",
       "      <td>The Most Complete Guide to PyTorch for Data Sc...</td>\n",
       "      <td>mlwhiz</td>\n",
       "      <td>https://towardsdatascience.com/@mlwhiz</td>\n",
       "      <td>All the PyTorch functionality you will ever…</td>\n",
       "      <td>706</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://towardsdatascience.com/using-genetic-a...</td>\n",
       "      <td>Using Genetic Algorithms to Train Neural Networks</td>\n",
       "      <td>vs1324</td>\n",
       "      <td>https://towardsdatascience.com/@vs1324</td>\n",
       "      <td></td>\n",
       "      <td>213</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://towardsdatascience.com/compas-case-stu...</td>\n",
       "      <td>COMPAS Case Study: Fairness of a Machine Learn...</td>\n",
       "      <td>farhanrahman02</td>\n",
       "      <td>https://towardsdatascience.com/@farhanrahman02</td>\n",
       "      <td></td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51863</th>\n",
       "      <td>https://medium.com/@vandomed/for-second-consec...</td>\n",
       "      <td>For Second Consecutive Presidential Election, ...</td>\n",
       "      <td>vandomed</td>\n",
       "      <td>https://medium.com/@vandomed</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51864</th>\n",
       "      <td>https://medium.com/@maxdymel/2019-vs-2020-the-...</td>\n",
       "      <td>2019 vs. 2020 — The last Formula 1 seasons com...</td>\n",
       "      <td>maxdymel</td>\n",
       "      <td>https://medium.com/@maxdymel</td>\n",
       "      <td>The 2020 Formula 1 season is over. With…</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51865</th>\n",
       "      <td>https://medium.com/@jmexclusives/why-are-uniqu...</td>\n",
       "      <td>Why are Unique Visitors so Important in Websit...</td>\n",
       "      <td>jmexclusives</td>\n",
       "      <td>https://medium.com/@jmexclusives</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51866</th>\n",
       "      <td>https://medium.com/@bryancjavier/periodismo-de...</td>\n",
       "      <td>Periodismo de Analytics</td>\n",
       "      <td>bryancjavier</td>\n",
       "      <td>https://medium.com/@bryancjavier</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>https://medium.com/bold-bi/balanced-scorecard-...</td>\n",
       "      <td>Balanced Scorecard Dashboard — Adding Value to BI</td>\n",
       "      <td>masilamani.chidambaram</td>\n",
       "      <td>https://medium.com/@masilamani.chidambaram</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34053 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      https://towardsdatascience.com/text-classifica...   \n",
       "1      https://towardsdatascience.com/predictive-main...   \n",
       "2      https://towardsdatascience.com/minimal-pytorch...   \n",
       "3      https://towardsdatascience.com/using-genetic-a...   \n",
       "4      https://towardsdatascience.com/compas-case-stu...   \n",
       "...                                                  ...   \n",
       "51863  https://medium.com/@vandomed/for-second-consec...   \n",
       "51864  https://medium.com/@maxdymel/2019-vs-2020-the-...   \n",
       "51865  https://medium.com/@jmexclusives/why-are-uniqu...   \n",
       "51866  https://medium.com/@bryancjavier/periodismo-de...   \n",
       "51867  https://medium.com/bold-bi/balanced-scorecard-...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      BERT for Text Classification with NO model tra...   \n",
       "1             Predictive maintenance of turbofan engines   \n",
       "2      The Most Complete Guide to PyTorch for Data Sc...   \n",
       "3      Using Genetic Algorithms to Train Neural Networks   \n",
       "4      COMPAS Case Study: Fairness of a Machine Learn...   \n",
       "...                                                  ...   \n",
       "51863  For Second Consecutive Presidential Election, ...   \n",
       "51864  2019 vs. 2020 — The last Formula 1 seasons com...   \n",
       "51865  Why are Unique Visitors so Important in Websit...   \n",
       "51866                            Periodismo de Analytics   \n",
       "51867  Balanced Scorecard Dashboard — Adding Value to BI   \n",
       "\n",
       "                       author                                     author_page  \\\n",
       "0                 mdipietro09     https://towardsdatascience.com/@mdipietro09   \n",
       "1                    kpeters_        https://towardsdatascience.com/@kpeters_   \n",
       "2                      mlwhiz          https://towardsdatascience.com/@mlwhiz   \n",
       "3                      vs1324          https://towardsdatascience.com/@vs1324   \n",
       "4              farhanrahman02  https://towardsdatascience.com/@farhanrahman02   \n",
       "...                       ...                                             ...   \n",
       "51863                vandomed                    https://medium.com/@vandomed   \n",
       "51864                maxdymel                    https://medium.com/@maxdymel   \n",
       "51865            jmexclusives                https://medium.com/@jmexclusives   \n",
       "51866            bryancjavier                https://medium.com/@bryancjavier   \n",
       "51867  masilamani.chidambaram      https://medium.com/@masilamani.chidambaram   \n",
       "\n",
       "                                               subtitle  claps responses  \\\n",
       "0      Use BERT, Word Embedding, and Vector Similarity…    278         6   \n",
       "1                                                          151         0   \n",
       "2          All the PyTorch functionality you will ever…    706         3   \n",
       "3                                                          213         7   \n",
       "4                                                           56         0   \n",
       "...                                                 ...    ...       ...   \n",
       "51863                                                        0         0   \n",
       "51864          The 2020 Formula 1 season is over. With…      0         0   \n",
       "51865                                                        0         0   \n",
       "51866                                                        0         0   \n",
       "51867                                                        0         0   \n",
       "\n",
       "       reading_time           tag        date  \n",
       "0                14  Data Science  2020-09-07  \n",
       "1                 9  Data Science  2020-09-07  \n",
       "2                14  Data Science  2020-09-07  \n",
       "3                 5  Data Science  2020-09-07  \n",
       "4                 8  Data Science  2020-09-07  \n",
       "...             ...           ...         ...  \n",
       "51863             2     Analytics  2020-12-31  \n",
       "51864             5     Analytics  2020-12-31  \n",
       "51865            10     Analytics  2020-12-31  \n",
       "51866             3     Analytics  2020-12-31  \n",
       "51867             6     Analytics  2020-12-31  \n",
       "\n",
       "[34053 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357bf600",
   "metadata": {},
   "source": [
    "## Save Collected data into csv file\n",
    "\n",
    "We save our data frame into a csv file named medium_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb0ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_df.to_csv('medium_data.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a1e0e",
   "metadata": {},
   "source": [
    "Hope you enjoy this notebook, feel free to give sugestion or submit PRs.\n",
    "\n",
    "Made with love by @viniciusLambert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
